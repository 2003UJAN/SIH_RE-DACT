{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003UJAN/SIH_RE-DACT/blob/main/ReDact_Text%2CImage%2CAudio%2CVideo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6Fg3vShLUil",
        "outputId": "20b637ed-df63-4352-fc2b-63bb2d38ca26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: speechrecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (43.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography) (2.22)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install spacy opencv-python moviepy speechrecognition gtts cryptography"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfZCfc4f1se",
        "outputId": "0034d572-1a10-4f16-85aa-60eafa6c660d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "gp8_t9grIeqi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "from transformers import pipeline\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import speech_recognition as sr\n",
        "import cv2\n",
        "import os\n",
        "import logging\n",
        "import moviepy.editor as mp\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from cryptography.fernet import Fernet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fxl9QohIhc6",
        "outputId": "e06b1548-4c30-4014-ceea-d3e2e897a634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "model = BertForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "1BeQAq8DIkqY"
      },
      "outputs": [],
      "source": [
        "encryption_key = Fernet.generate_key()\n",
        "cipher_suite = Fernet(encryption_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ePAxpFn5IlO6"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(filename='redaction_tool.log', level=logging.INFO, format='%(asctime)s %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "7OTVdiSFIngu"
      },
      "outputs": [],
      "source": [
        "def perform_ner(text):\n",
        "    entities = nlp(text)\n",
        "    entity_list = [(ent['word'], ent['entity']) for ent in entities]\n",
        "    return entity_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xz2_PPBVIrY1"
      },
      "outputs": [],
      "source": [
        "def sanitize_input(input_str):\n",
        "    return input_str.replace(';', '').replace('&', '').replace('|', '').strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2fH5OAPSIwiD"
      },
      "outputs": [],
      "source": [
        "def redact_text(text, entities, degree):\n",
        "    for entity, label in entities:\n",
        "        if degree == 1 and label in [\"B-PER\", \"B-ORG\"]:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "        elif degree == 2 and label in [\"B-PER\", \"B-ORG\", \"B-DATE\"]:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "        elif degree == 3:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "dPdxX3-yI0Ha"
      },
      "outputs": [],
      "source": [
        "def save_text_file(content, filename=\"redacted_text.txt\"):\n",
        "    sanitized_filename = sanitize_input(filename)\n",
        "    with open(sanitized_filename, 'w') as file:\n",
        "        file.write(content)\n",
        "    logging.info(f\"Redacted text saved as {sanitized_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "9Fg8QpAlI1Fe"
      },
      "outputs": [],
      "source": [
        "def encrypt_file_content(content):\n",
        "    return cipher_suite.encrypt(content.encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "xJGaCDduI4x8"
      },
      "outputs": [],
      "source": [
        "def decrypt_file_content(content):\n",
        "    return cipher_suite.decrypt(content).decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "DURHn-jII766"
      },
      "outputs": [],
      "source": [
        "def redact_image_with_haar(image_path, degree=1):\n",
        "    sanitized_image_path = sanitize_input(image_path)\n",
        "    if not os.path.exists(sanitized_image_path):\n",
        "        logging.error(f\"File not found: {sanitized_image_path}\")\n",
        "        return None\n",
        "\n",
        "    image = cv2.imread(sanitized_image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        if degree == 1:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            blurred_face = cv2.GaussianBlur(face, (99, 99), 30)\n",
        "            image[y:y+h, x:x+w] = blurred_face\n",
        "        elif degree == 2:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            small_face = cv2.resize(face, (w // 10, h // 10), interpolation=cv2.INTER_LINEAR)\n",
        "            resized_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "            image[y:y+h, x:x+w] = resized_face\n",
        "        elif degree == 3:\n",
        "            image[y:y+h, x:x+w] = 0\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "sXQVuQzNJZ00"
      },
      "outputs": [],
      "source": [
        "def save_image_file(image, filename=\"redacted_image.jpg\"):\n",
        "    sanitized_filename = sanitize_input(filename)\n",
        "    cv2.imwrite(sanitized_filename, image)\n",
        "    logging.info(f\"Redacted image saved as {sanitized_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YPooLX7EJchg"
      },
      "outputs": [],
      "source": [
        "def redact_video_with_haar(video_path, degree=1):\n",
        "    sanitized_video_path = sanitize_input(video_path)\n",
        "    if not os.path.exists(sanitized_video_path):\n",
        "        logging.error(f\"File not found: {sanitized_video_path}\")\n",
        "        return None\n",
        "\n",
        "    cap = cv2.VideoCapture(sanitized_video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(f'redacted_{os.path.basename(sanitized_video_path)}', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            if degree == 1:\n",
        "                face = frame[y:y+h, x:x+w]\n",
        "                blurred_face = cv2.GaussianBlur(face, (99, 99), 30)\n",
        "                frame[y:y+h, x:x+w] = blurred_face\n",
        "            elif degree == 2:\n",
        "                face = frame[y:y+h, x:x+w]\n",
        "                small_face = cv2.resize(face, (w // 10, h // 10), interpolation=cv2.INTER_LINEAR)\n",
        "                resized_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "                frame[y:y+h, x:x+w] = resized_face\n",
        "            elif degree == 3:\n",
        "                frame[y:y+h, x:x+w] = 0\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    logging.info(f\"Redacted video saved as redacted_{os.path.basename(sanitized_video_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "PhguCBwvJstg"
      },
      "outputs": [],
      "source": [
        "def convert_audio_to_wav(audio_path):\n",
        "    sanitized_audio_path = sanitize_input(audio_path)\n",
        "    audio = AudioSegment.from_file(sanitized_audio_path)\n",
        "    wav_path = f\"{os.path.splitext(sanitized_audio_path)[0]}.wav\"\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "    return wav_path\n",
        "\n",
        "def synthesize_speech(text, filename=\"output.wav\"):\n",
        "    from pydub.generators import Sine\n",
        "\n",
        "    speech = Sine(440).to_audio_segment(duration=len(text) * 50)  # Fake audio for illustration\n",
        "    # In reality, you'd replace the Sine generator with real TTS or use another method.\n",
        "    speech.export(filename, format=\"wav\")\n",
        "\n",
        "def redact_audio(audio_path, degree=1):\n",
        "    try:\n",
        "        wav_audio_path = convert_audio_to_wav(audio_path)\n",
        "        recognizer = sr.Recognizer()\n",
        "        audio_file = sr.AudioFile(wav_audio_path)\n",
        "\n",
        "        with audio_file as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "\n",
        "        text = recognizer.recognize_google(audio_data)\n",
        "        entities = perform_ner(text)\n",
        "        redacted_text = redact_text(text, entities, degree)\n",
        "\n",
        "        redacted_audio_path = f'redacted_{os.path.basename(wav_audio_path)}'\n",
        "        synthesize_speech(redacted_text, redacted_audio_path)\n",
        "\n",
        "        logging.info(f\"Redacted audio saved as {redacted_audio_path}\")\n",
        "    except sr.UnknownValueError:\n",
        "        logging.error(\"Could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        logging.error(f\"Error with the speech recognition service; {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-VO-9m2iJwYu"
      },
      "outputs": [],
      "source": [
        "def chatbot():\n",
        "    print(\"Welcome to the Redaction Tool Chatbot! How can I help you today?\")\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Redact Text\")\n",
        "        print(\"2. Redact Image\")\n",
        "        print(\"3. Redact Video\")\n",
        "        print(\"4. Redact Audio\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"Choose an option: \")\n",
        "\n",
        "        if choice == '1':\n",
        "            text = input(\"Please enter the text you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Redact names of people and organizations.\")\n",
        "            print(\"2. Redact names of people, organizations, and dates.\")\n",
        "            print(\"3. Redact all detected entities.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            entities = perform_ner(text)\n",
        "            redacted_text = redact_text(text, entities, degree)\n",
        "            encrypted_text = encrypt_file_content(redacted_text)\n",
        "            save_text_file(encrypted_text.decode('utf-8'))\n",
        "            print(\"Text has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            image_path = input(\"Please enter the path of the image you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Blur detected faces.\")\n",
        "            print(\"2. Pixelate detected faces.\")\n",
        "            print(\"3. Black out detected faces.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redacted_image = redact_image_with_haar(image_path, degree)\n",
        "            if redacted_image is not None:\n",
        "                save_image_file(redacted_image)\n",
        "                print(\"Image has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            video_path = input(\"Please enter the path of the video you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Blur detected faces.\")\n",
        "            print(\"2. Pixelate detected faces.\")\n",
        "            print(\"3. Black out detected faces.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redact_video_with_haar(video_path, degree)\n",
        "            print(\"Video has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            audio_path = input(\"Please enter the path of the audio file you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Redact names of people and organizations in the audio.\")\n",
        "            print(\"2. Redact names of people, organizations, and dates in the audio.\")\n",
        "            print(\"3. Redact all detected entities in the audio.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redact_audio(audio_path, degree)\n",
        "            print(\"Audio has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please choose a valid option.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFgspXx2J0hY",
        "outputId": "d5854a7e-d06f-4db7-a5c0-bde10ef15866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Redaction Tool Chatbot! How can I help you today?\n",
            "\n",
            "Options:\n",
            "1. Redact Text\n",
            "2. Redact Image\n",
            "3. Redact Video\n",
            "4. Redact Audio\n",
            "5. Exit\n",
            "Choose an option: 4\n",
            "Please enter the path of the audio file you would like to redact: /content/Ujan_Voice_3.mp4\n",
            "Redaction levels:\n",
            "1. Redact names of people and organizations in the audio.\n",
            "2. Redact names of people, organizations, and dates in the audio.\n",
            "3. Redact all detected entities in the audio.\n",
            "Choose the redaction level (1-3): 1\n",
            "Audio has been redacted and saved.\n",
            "\n",
            "Options:\n",
            "1. Redact Text\n",
            "2. Redact Image\n",
            "3. Redact Video\n",
            "4. Redact Audio\n",
            "5. Exit\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjGQpKJInO+qwqSHTAAFrN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}