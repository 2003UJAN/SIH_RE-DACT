{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkSIHnxk9004leA9vfzgQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003UJAN/SIH_RE-DACT/blob/main/ReDact_Text%2CImage%2CAudio%2CVideo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy opencv-python moviepy speechrecognition gtts cryptography"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6Fg3vShLUil",
        "outputId": "5350ac7b-f2df-43bf-ff69-0860cec05ec0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: speechrecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (43.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography) (2.22)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gp8_t9grIeqi"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import cv2\n",
        "import os\n",
        "import logging\n",
        "import moviepy.editor as mp\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from cryptography.fernet import Fernet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "5fxl9QohIhc6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encryption_key = Fernet.generate_key()\n",
        "cipher_suite = Fernet(encryption_key)"
      ],
      "metadata": {
        "id": "1BeQAq8DIkqY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(filename='redaction_tool.log', level=logging.INFO, format='%(asctime)s %(message)s')"
      ],
      "metadata": {
        "id": "ePAxpFn5IlO6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_ner(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities"
      ],
      "metadata": {
        "id": "7OTVdiSFIngu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_input(input_str):\n",
        "    return input_str.replace(';', '').replace('&', '').replace('|', '').strip()"
      ],
      "metadata": {
        "id": "xz2_PPBVIrY1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_text(text, entities, degree):\n",
        "    for entity, label in entities:\n",
        "        if degree == 1 and label in [\"PERSON\", \"ORG\"]:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "        elif degree == 2 and label in [\"PERSON\", \"ORG\", \"DATE\"]:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "        elif degree == 3:\n",
        "            text = text.replace(entity, \"[REDACTED]\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "2fH5OAPSIwiD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_text_file(content, filename=\"redacted_text.txt\"):\n",
        "    sanitized_filename = sanitize_input(filename)\n",
        "    with open(sanitized_filename, 'w') as file:\n",
        "        file.write(content)\n",
        "    logging.info(f\"Redacted text saved as {sanitized_filename}\")"
      ],
      "metadata": {
        "id": "dPdxX3-yI0Ha"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encrypt_file_content(content):\n",
        "    return cipher_suite.encrypt(content.encode('utf-8'))"
      ],
      "metadata": {
        "id": "9Fg8QpAlI1Fe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt_file_content(content):\n",
        "    return cipher_suite.decrypt(content).decode('utf-8')"
      ],
      "metadata": {
        "id": "xJGaCDduI4x8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_image_with_haar(image_path, degree=1):\n",
        "    sanitized_image_path = sanitize_input(image_path)\n",
        "    if not os.path.exists(sanitized_image_path):\n",
        "        logging.error(f\"File not found: {sanitized_image_path}\")\n",
        "        return None\n",
        "\n",
        "    image = cv2.imread(sanitized_image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        if degree == 1:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            blurred_face = cv2.GaussianBlur(face, (99, 99), 30)\n",
        "            image[y:y+h, x:x+w] = blurred_face\n",
        "        elif degree == 2:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            small_face = cv2.resize(face, (w // 10, h // 10), interpolation=cv2.INTER_LINEAR)\n",
        "            resized_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "            image[y:y+h, x:x+w] = resized_face\n",
        "        elif degree == 3:\n",
        "            image[y:y+h, x:x+w] = 0\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "DURHn-jII766"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image_file(image, filename=\"redacted_image.jpg\"):\n",
        "    sanitized_filename = sanitize_input(filename)\n",
        "    cv2.imwrite(sanitized_filename, image)\n",
        "    logging.info(f\"Redacted image saved as {sanitized_filename}\")"
      ],
      "metadata": {
        "id": "sXQVuQzNJZ00"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_video_with_haar(video_path, degree=1):\n",
        "    sanitized_video_path = sanitize_input(video_path)\n",
        "    if not os.path.exists(sanitized_video_path):\n",
        "        logging.error(f\"File not found: {sanitized_video_path}\")\n",
        "        return None\n",
        "\n",
        "    cap = cv2.VideoCapture(sanitized_video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(f'redacted_{os.path.basename(sanitized_video_path)}', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            if degree == 1:\n",
        "                face = frame[y:y+h, x:x+w]\n",
        "                blurred_face = cv2.GaussianBlur(face, (99, 99), 30)\n",
        "                frame[y:y+h, x:x+w] = blurred_face\n",
        "            elif degree == 2:\n",
        "                face = frame[y:y+h, x:x+w]\n",
        "                small_face = cv2.resize(face, (w // 10, h // 10), interpolation=cv2.INTER_LINEAR)\n",
        "                resized_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "                frame[y:y+h, x:x+w] = resized_face\n",
        "            elif degree == 3:\n",
        "                frame[y:y+h, x:x+w] = 0\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    logging.info(f\"Redacted video saved as redacted_{os.path.basename(sanitized_video_path)}\")"
      ],
      "metadata": {
        "id": "YPooLX7EJchg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_audio(audio_path, degree=1):\n",
        "    sanitized_audio_path = sanitize_input(audio_path)\n",
        "    if not os.path.exists(sanitized_audio_path):\n",
        "        logging.error(f\"File not found: {sanitized_audio_path}\")\n",
        "        return None\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "    audio_file = sr.AudioFile(sanitized_audio_path)\n",
        "\n",
        "    with audio_file as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio_data)\n",
        "        entities = perform_ner(text)\n",
        "        redacted_text = redact_text(text, entities, degree)\n",
        "\n",
        "        tts = gTTS(redacted_text)\n",
        "        redacted_audio_path = f'redacted_{os.path.basename(sanitized_audio_path)}'\n",
        "        tts.save(redacted_audio_path)\n",
        "\n",
        "        logging.info(f\"Redacted audio saved as {redacted_audio_path}\")\n",
        "    except sr.UnknownValueError:\n",
        "        logging.error(\"Could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        logging.error(f\"Error with the speech recognition service; {e}\")"
      ],
      "metadata": {
        "id": "PhguCBwvJstg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot():\n",
        "    print(\"Welcome to the Redaction Tool Chatbot! How can I help you today?\")\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Redact Text\")\n",
        "        print(\"2. Redact Image\")\n",
        "        print(\"3. Redact Video\")\n",
        "        print(\"4. Redact Audio\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"Choose an option: \")\n",
        "\n",
        "        if choice == '1':\n",
        "            text = input(\"Please enter the text you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Redact names of people and organizations.\")\n",
        "            print(\"2. Redact names of people, organizations, and dates.\")\n",
        "            print(\"3. Redact all detected entities.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            entities = perform_ner(text)\n",
        "            redacted_text = redact_text(text, entities, degree)\n",
        "            encrypted_text = encrypt_file_content(redacted_text)\n",
        "            save_text_file(encrypted_text.decode('utf-8'))\n",
        "            print(\"Text has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            image_path = input(\"Please enter the path of the image you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Blur detected faces.\")\n",
        "            print(\"2. Pixelate detected faces.\")\n",
        "            print(\"3. Black out detected faces.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redacted_image = redact_image_with_haar(image_path, degree)\n",
        "            if redacted_image is not None:\n",
        "                save_image_file(redacted_image)\n",
        "                print(\"Image has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            video_path = input(\"Please enter the path of the video you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Blur detected faces.\")\n",
        "            print(\"2. Pixelate detected faces.\")\n",
        "            print(\"3. Black out detected faces.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redact_video_with_haar(video_path, degree)\n",
        "            print(\"Video has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            audio_path = input(\"Please enter the path of the audio file you would like to redact: \")\n",
        "            print(\"Redaction levels:\")\n",
        "            print(\"1. Redact names of people and organizations in the audio.\")\n",
        "            print(\"2. Redact names of people, organizations, and dates in the audio.\")\n",
        "            print(\"3. Redact all detected entities in the audio.\")\n",
        "            degree = int(input(\"Choose the redaction level (1-3): \"))\n",
        "            redact_audio(audio_path, degree)\n",
        "            print(\"Audio has been redacted and saved.\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please choose a valid option.\")"
      ],
      "metadata": {
        "id": "-VO-9m2iJwYu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFgspXx2J0hY",
        "outputId": "30ac523d-9783-40f4-84bc-22a6f98f29f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Redaction Tool Chatbot! How can I help you today?\n",
            "\n",
            "Options:\n",
            "1. Redact Text\n",
            "2. Redact Image\n",
            "3. Redact Video\n",
            "4. Redact Audio\n",
            "5. Exit\n",
            "Choose an option: 2\n",
            "Please enter the path of the image you would like to redact: /content/SIH_Redact_1.jpg\n",
            "Redaction levels:\n",
            "1. Blur detected faces.\n",
            "2. Pixelate detected faces.\n",
            "3. Black out detected faces.\n",
            "Choose the redaction level (1-3): 2\n",
            "Image has been redacted and saved.\n",
            "\n",
            "Options:\n",
            "1. Redact Text\n",
            "2. Redact Image\n",
            "3. Redact Video\n",
            "4. Redact Audio\n",
            "5. Exit\n",
            "Choose an option: 5\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}